¿Cuáles son las propiedades esenciales que definen a un algoritmo?;Un algoritmo es una secuencia de instrucciones que debe ser:<br>1. **Finita:** Termina después de un número finito de pasos.<br>2. **Ordenada y Explícita:** Los pasos están claramente secuenciados.<br>3. **Precisa y No Ambigua:** Cada instrucción tiene un único significado.<br>4. **Mecánicamente Ejecutable:** No requiere intuición o creatividad para ser ejecutado.
¿Por qué no es una buena práctica comparar algoritmos simplemente midiendo el tiempo de ejecución de sus programas?;Porque el tiempo medido es una propiedad del **programa**, no del **algoritmo**. Dicho tiempo depende de factores externos como:<br>- El hardware (CPU, memoria).<br>- El sistema operativo.<br>- El lenguaje de programación y el compilador.<br>- La habilidad del programador.
¿Qué es la "función de costo" en el análisis de algoritmos?;Es una función \(c\) que asigna un valor numérico no negativo al consumo de un recurso específico por un algoritmo \(A\) al procesar una entrada particular \(d\).<br><br>Formalmente: \( c: \mathcal{A} \times D \to \mathbb{R}_0^+ \), donde \(\mathcal{A}\) es la familia de algoritmos y \(D\) el universo de datos.
¿Qué representa el "vector de costos" de un algoritmo \(A\)?;\(\vec{c}_A\) es un vector donde cada componente representa el costo del algoritmo \(A\) para una entrada específica del universo de datos \(D\).<br>\[ \vec{c}_A = (c(A, d_1), c(A, d_2), c(A, d_3), \dots) \]
¿Para qué sirve una "función de evaluación" \(e\) en el análisis de algoritmos?;Sirve para condensar o resumir toda la información de un vector de costos \(\vec{c}_A\) en un **único valor numérico**, permitiendo así una comparación más sencilla entre dos algoritmos.<br><br>Formalmente: \[ e: (\mathbb{R}_0^+)^{|D|} \to \mathbb{R}_0^+ \]
¿Qué es el análisis de "peor caso" y qué función de evaluación utiliza?;Es un análisis que se enfoca en el máximo costo posible que un algoritmo puede tener sobre cualquier entrada. Utiliza la función de evaluación **Máximo**.<br>\[ e(\vec{c}) = \max_{d \in D}(c(A,d)) \]
¿En qué situaciones es más conveniente utilizar el análisis de peor caso (Máximo)?;Es crucial en sistemas interactivos o de tiempo real, donde una sola respuesta lenta puede arruinar la experiencia del usuario o causar una falla crítica. Ejemplo: el tiempo de respuesta de un cajero automático o un sistema de frenos de un coche.
¿Qué es el análisis de "caso promedio" y qué función de evaluación utiliza?;Es un análisis que calcula el costo promedio de un algoritmo, ponderando el costo de cada entrada por su probabilidad de ocurrencia. Utiliza la función de evaluación **Esperanza** (o Promedio si los datos son isoprobables).<br>\[ e(\vec{c}) = \sum_{d \in D} P(d) \cdot c(A,d) \]
Una afirmación como "El algoritmo A es mejor que el B" es incompleta. ¿Cómo se debe formular correctamente?;Se debe especificar tanto la métrica de costo como la función de evaluación. Por ejemplo:<br>"El algoritmo A es mejor que el B **midiendo la cantidad de comparaciones como costo** y **evaluando por el peor caso (máximo)**".
¿Qué es el análisis asintótico y por qué es necesario?;Es el estudio del comportamiento del costo de un algoritmo a medida que el tamaño de la entrada (\(n\)) tiende a infinito. Es necesario para entender cómo **escala** un algoritmo, independientemente del rendimiento en entradas pequeñas.
Define la notación **\(O\) (Big O)**.;Big O describe una **cota superior** asintótica. Decimos que \(g(n)\) es \(O(f(n))\) si \(g(n)\) no crece más rápido que \(f(n)\) para valores de \(n\) suficientemente grandes.<br><br>**Definición Formal:**<br>\[ g(n) \in O(f(n)) \iff \exists c > 0, n_0 \ge 0 \text{ tal que } \forall n \ge n_0, g(n) \le c \cdot f(n) \]
Define la notación **\(\Omega\) (Big Omega)**.;Big Omega describe una **cota inferior** asintótica. Decimos que \(g(n)\) es \(\Omega(f(n))\) si \(g(n)\) crece al menos tan rápido como \(f(n)\) para valores de \(n\) suficientemente grandes.<br><br>**Definición Formal:**<br>\[ g(n) \in \Omega(f(n)) \iff \exists c > 0, n_0 \ge 0 \text{ tal que } \forall n \ge n_0, g(n) \ge c \cdot f(n) \]
Define la notación **\(\Theta\) (Big Theta)**.;Big Theta describe una **cota ajustada** asintótica. Decimos que \(g(n)\) es \(\Theta(f(n))\) si \(g(n)\) crece a la misma tasa que \(f(n)\) para valores de \(n\) suficientemente grandes.<br><br>**Definición Formal:**<br>\[ g(n) \in \Theta(f(n)) \iff \exists c_1, c_2 > 0, n_0 \ge 0 \text{ tal que } \forall n \ge n_0, c_1 \cdot f(n) \le g(n) \le c_2 \cdot f(n) \]
Describe visualmente las cotas asintóticas \(O, \Omega\) y \(\Theta\).;**Visualización:**<br><b>(a) \(\Theta(f)\):</b> \(g(n)\) está "atrapada" entre \(c_1f(n)\) y \(c_2f(n)\).<br><b>(b) \(O(f)\):</b> \(g(n)\) está por debajo de \(cf(n)\).<br><b>(c) \(\Omega(f)\):</b> \(g(n)\) está por encima de \(cf(n)\).<br><br>*(Gráficos conceptuales mostrados en el documento original)*
¿Cuál es el teorema que relaciona las notaciones \(O, \Omega\) y \(\Theta\) ?;Unha función \(g(n)\) pertenece a \(\Theta(f(n))\) si y solo si pertenece tanto a \(O(f(n))\) como a \(\Omega(f(n))\).<br>\[ g(n) \in \Theta(f(n)) \iff g(n) \in O(f(n)) \land g(n) \in \Omega(f(n)) \]
Demuestra que la función \(g(n) = 5n^2 + 3n + 12\) pertenece a \(\Theta(n^2)\).;Debemos encontrar constantes \(c_1, c_2 > 0\) y un \(n_0\) tal que para todo \(n \ge n_0\):<br>\[ c_1 n^2 \le 5n^2 + 3n + 12 \le c_2 n^2 \]<br>Dividiendo todo por \(n^2\):<br>\[ c_1 \le 5 + \frac{3}{n} + \frac{12}{n^2} \le c_2 \]<br>Para \(n \ge 1\), la expresión del medio es \(\le 5+3+12 = 20\). Podemos elegir \(c_2 = 20\).<br>A medida que \(n \to \infty\), la expresión tiende a 5. Para \(n \ge 1\), la expresión es \( > 5\). Podemos elegir \(c_1 = 5\).<br>Por lo tanto, con \(c_1 = 5\), \(c_2 = 20\) y \(n_0 = 1\), la condición se cumple.
¿Cuál es el orden de crecimiento de las clases de complejidad más comunes?;De más lento (mejor) a más rápido (peor):<br>\(O(1)\) (constante) < \(O(\log n)\) (logarítmico) < \(O(n)\) (lineal) < \(O(n \log n)\) (linealítmico) < \(O(n^2)\) (cuadrático) < \(O(n^3)\) (cúbico) < \(O(2^n)\) (exponencial).
¿Qué es la complejidad de un problema P?;Es el costo del **mejor algoritmo posible** para resolver P. Se define como el mínimo de los costos de todos los algoritmos en la familia \(\mathcal{A}\) que resuelven el problema.<br><br>\[ \text{complejidad}_{e-c}(P) = \min_{A \in \mathcal{A}} (e(c(A,D))) \]
¿Cuál es la diferencia entre un algoritmo "óptimo" y uno "optimal"?;Un algoritmo es **óptimo** si es el **único** que alcanza la complejidad mínima para un problema.<br>Si **varios** algoritmos alcanzan esa complejidad mínima, se dice que todos ellos son **optimales**.